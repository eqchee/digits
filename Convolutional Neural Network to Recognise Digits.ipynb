{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network to Recognise Digits\n",
    "\n",
    "## About The Project\n",
    "\n",
    "Deep Learning was performed by creating a Convolutional Neural Network (CNN) using TensorFlow to identify handwritten digits on images. This was achieved by preparing the data and then performing CNN modelling and evaluation. An accuracy of 98.8% was achieved when the predictions were submitted to Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x181992cf940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is roughly similar number of samples for the 10 digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       785\n",
      "unique        1\n",
      "top       False\n",
      "freq        785\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().any().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the provided data into train and validation images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(data, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31500, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 785)\n"
     ]
    }
   ],
   "source": [
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('label', axis=1)\n",
    "X_val = val.drop('label', axis=1)\n",
    "y_train = train.label\n",
    "y_val = val.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data to form images of size 28px by 28px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31500, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_val = X_val.values.reshape(-1,28,28,1)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_val = np.asarray(X_val)\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Convolutional Neural Network (CNN) is structured to reduce the images into a form which is easier to process while retaining important features to obtain good prediction: \n",
    "- Convolutional layer (Conv2D) can isolate useful features from the images\n",
    "- Pooling layer (MaxPooling2D) helps with dimensionality reduction, facilitating the extraction of dominant features. \n",
    "- Dropout layer is for regularization to reduce overfitting\n",
    "- Flatten layer converts the feature maps into a single 1D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31500 samples, validate on 10500 samples\n",
      "Epoch 1/5\n",
      "31500/31500 [==============================] - 40s 1ms/sample - loss: 0.3563 - accuracy: 0.8858 - val_loss: 0.0907 - val_accuracy: 0.9725\n",
      "Epoch 2/5\n",
      "31500/31500 [==============================] - 38s 1ms/sample - loss: 0.1319 - accuracy: 0.9592 - val_loss: 0.0642 - val_accuracy: 0.9801\n",
      "Epoch 3/5\n",
      "31500/31500 [==============================] - 38s 1ms/sample - loss: 0.1003 - accuracy: 0.9699 - val_loss: 0.0484 - val_accuracy: 0.9850\n",
      "Epoch 4/5\n",
      "31500/31500 [==============================] - 36s 1ms/sample - loss: 0.0840 - accuracy: 0.9740 - val_loss: 0.0475 - val_accuracy: 0.9849\n",
      "Epoch 5/5\n",
      "31500/31500 [==============================] - 33s 1ms/sample - loss: 0.0704 - accuracy: 0.9771 - val_loss: 0.0412 - val_accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val), callbacks=[EarlyStopping(patience=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(filepath,\"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ImageId': pd.Series(range(1,28001)),\n",
    "    'Label': prediction\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions from the above model were submitted to Kaggle and achieved 98.8% accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
